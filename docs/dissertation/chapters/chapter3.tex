\chapter{ACOMUS Database}
The ACOMUS Database is the database we used in our ASR system in music,which is designed by Gerardo Roa Dabike. It concludes 240 English songs covered by amateur singers that are collected from YouTube. Among these songs, 200 songs are accompanied by guitar and the left 40 songs are accompanied by piano. Each song in this database has a unique song id, which composed by information of gender, sequence number of artist and instrument. For example song id:F002\_002\_01\_0101, F002 stands for the information that the second amateur singer in database's singer list is female, the following 002 means this song is the second song in song's list, and o1 represents guitar.
To look through the unique id in database, it is clear to see there are 174 amateur singers and 213 different songs in this database.


\section{ACOMUS2 Corpus}
Acoustic Cover Music Corpus 2 is a collection of isolated audio and video segments of every sentence in the singing parts of acoustic covers from amateur artist extracted from YouTube. The corpus is in English Language and the music has no restriction of style. The audio files are 16kHz sample-rated one channel files in wav format. And video files are in MPEG-4 format.For quality, the audios are accompanied with one instrument typically guitar or piano. Besides, some of the videos have low image resolution and the quantity of useful frames is small.

     
        
\subsection{Lyrics Annotation}
Lyrics is a computer file format that synchronizes song lyrics with an audio file[10]. For this project, we can only generate all the lyrics by hand for that the official lyrics would not match with the covers. We can observe the static lyrics from the website http://lyrics.wikia.com. However, it still need to check with every utterance in covers. Because the acoustic cover is not singer's official song, amateur artist may not follow the original lyrics with every utterance and sometimes they would changes some sentences in the original lyrics. Therefore, we need to modify the original lyrics to match with the cover. Moreover, we still need to segment the songs with individual sentences with methods of marking the time when every single sentence starts and stops and store them into json format in our database firstly. And then transfer them into kaldi format, only in that way it can be read by Kaldi and used in the last stage of ASR system when scoring the WER.   

\subsection{Audio and video files distribution}
As stated in the above section, the process of annotating songs consumes time and energy. In the ACOMUS Database, there are 120 songs been annotated. Even though the accumulation time of annotated songs is already not long for training acoustic models, not all the annotated utterances can be used especially in visual-only ASR system since it is picky to pick up good utterances to extract visual features. Here is the table \ref{tab:utterance} to show distribution of annotated utterances being used in audio-only ASR system and visual-only ASR system respectively.
\begin{table}[ht]
\center
\begin{tabular}{c|cc}
System & quantity of annotated utterances & time size of annotated utterances\\
\hline
A-ASR system & 3428 & 282 min\\
V-ASR system & 1013 & 83 min\\

\end{tabular}
\caption{System distribution of used utterances}
\label{tab:utterance}
\end{table}



\section{Language Model}
In order to generate a suitable language model for our ASR system in music. It is better to collect the lyrics with the similar style of songs in our database. 
Therefore, the language model is based on a lyrics corpus composed by other songs from the same 157 original singer in database. In addition, another 39 popular singers would be appended to our singer's list. At last, the lyrics corpus is generated by 25916 songs from these 196 singers.

\section{Acoustic Model}

The pronunciation of phonemes in our acoustic model is based on CMUdict, a dictionary has 39 phonemes and 133,031 different words. Aiming to keep the model to be simple, only 5000 words are selected from the dictionary. The rules of selecting these 5000 words are to keep as many as words in annotated utterance. However, there are only 3500 words can be generated from our database (among 240 songs). To complete the construction of 5k words, the left 1500 words were generated by random.

Finally, we generated the 5k words and saved it as lexicon.txt according to the annotated utterances.

