\chapter*{\Large \center Abstract}

Lip-reading for song transcription is a specific topic on the research of visual automatic speech recognition in music. In a traditional dialogue, people recognize the speech content through their auditory sense, visual sense and also according to the circumstances with their own knowledge reserves. If compare audio recognition system to auditory sense, compare video recognition system to visual sense, compare language model to the circumstances, and compare lexicon to knowledge reserves, computer machine also can achieve the ability of recognizing the dialogue by huge training. It is a process of developing an audio-visual automatic speech recognition system. 

But for this project on song transcription, it extends an MSc project that ran last year called ‘Automatic Speech Recognition in Music’\cite{Reference1}. This year we will focus more on the visual front end design in ASR system and compare its performance with last year's audio-only ASR system. The visual-only ASR system would be trained with  traditional GMM-HMM methodologies. Since the experimental results are even more bad than last year's 91.60 percent WER with 98.49 percent WER,  more information on audio-visual fusion would be covered in our paper to prepare for the future's developing on AV-ASR system in music.

