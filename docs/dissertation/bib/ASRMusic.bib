@misc{HTK,
author = {{Cambridge University Engineering Department}},
keywords = {cambridge,computer speech,cstit,cued,entropic,hidden markov model,hmm,htk,htk3,internet technology,large vocabulary,phil woodland,speech recognition,steve young},
title = {{HTK Speech Recognition Toolkit}},
url = {http://htk.eng.cam.ac.uk/},
urldate = {2016-05-13}
}
@misc{SOX,
author = {Cbagwell and Robs and Uklauer},
keywords = {SOX},
title = {{SoX - Sound eXchange}},
url = {http://sox.sourceforge.net/Main/HomePage}
}
@misc{CMU,
author = {CMU},
title = {{The CMU Pronouncing Dictionary}},
url = {http://www.speech.cs.cmu.edu/cgi-bin/cmudict},
urldate = {2016-05-15}
}
@article{Federico2008,
author = {Federico, M and Bertoldi, N and Cettolo, M},
file = {:home/gerardo/Documents/Mendeley Desktop/Federico, Bertoldi, Cettolo - 2008 - IRST Language Modeling Toolkit USER MANUAL.pdf:pdf},
journal = {Language},
pages = {1--8},
title = {{IRST Language Modeling Toolkit USER MANUAL}},
year = {2008}
}
@misc{YouTubeDL,
author = {Gonzalez, Ricardo Garcia and Colligan, Danny and Johnson, Benjamin and Vavrychuk, Vasyl' and Baryluk, Witold and Paprota, Pawe{\l} and Imreh, Gergely and Hagemeister, Philipp and Schulze, S{\"{o}}ren and Valsorda, Filippo},
title = {youtube-dl},
url = {https://rg3.github.io/youtube-dl/},
urldate = {2016-05-13}
}
@article{Goto2004,
author = {Goto, Masataka and Itou, K and Kitayama, K},
file = {:home/gerardo/Documents/Mendeley Desktop/Goto, Itou, Kitayama - 2004 - Speech-recognition interfaces for music information retrieval.pdf:pdf},
journal = {Music Information Retrieval},
title = {{Speech-recognition interfaces for music information retrieval}},
url = {http://staff.aist.go.jp/m.goto/PAPER/ISMIR2004SLIDEgoto.pdf},
year = {2004}
}
@misc{Hain2016a,
address = {Sheffield},
author = {Hain, Thomas},
institution = {University of Sheffield},
pages = {26},
title = {{Speech Technology - Handout 3a - Neural Network in Speech Technology}},
year = {2016}
}
@article{Hinton2010,
abstract = {(by JL)Les recettes de cuisine de Hinton!Pas de d{\'{e}}tour par la th{\'{e}}orie, mais Hinton livre ses intuitions et son exp{\'{e}}rience.Des conseils pratiques sur comment entrainer les r{\'{e}}seaux, et comment v{\'{e}}rifier que l'entrainement se passe bien (notamment, des conseils pour la visualisation de ce qui se passe...).},
author = {Hinton, Geoffrey},
doi = {10.1007/978-3-642-35289-8_32},
file = {:home/gerardo/Documents/Mendeley Desktop/Hinton - 2010 - A Practical Guide to Training Restricted Boltzmann Machines A Practical Guide to Training Restricted Boltzmann Machines.pdf:pdf},
isbn = {978-3-642-35288-1},
issn = {364235288X},
journal = {Computer},
number = {3},
pages = {1},
title = {{A Practical Guide to Training Restricted Boltzmann Machines A Practical Guide to Training Restricted Boltzmann Machines}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.170.9573{\&}rep=rep1{\&}type=pdf},
volume = {9},
year = {2010}
}
@article{Lee2001,
abstract = {Julius is a high-performance, two-pass LVCSR decoder for researchers and developers. Based on word 3-gram and context-dependent HMM, it can perform almost real-time decoding on most current PCs in 20k word dictation task. Major search techniques are fully incorporated such as tree lexicon, N-gram factoring, cross-word context dependency handling, enveloped beam search, Gaussian pruning, Gaussian selection, etc. Besides search efficiency, it is also modularized carefully to be independent from model structures, and various HMM types are supported such as shared-state triphones and tied-mixture models, with any number of mixtures, states, or phones. Standard formats are adopted to cope with other free modeling toolkit. The main platform is Linux and other Unix workstations, and partially works on Windows. Julius is distributed with open license together with source codes, and has been used by many researchers and developers in Japan.},
author = {Lee, a. and Kawahara, T. and Shikano, K.},
file = {:home/gerardo/Documents/Mendeley Desktop/Lee, Kawahara, Shikano - 2001 - Julius — an Open Source Real-Time Large Vocabulary Recognition Engine.pdf:pdf},
journal = {Eurospeech},
pages = {1691--1694},
title = {{Julius — an Open Source Real-Time Large Vocabulary Recognition Engine}},
url = {http://www.isca-speech.org/archive/eurospeech{\_}2001/e01{\_}1691.html},
year = {2001}
}
@article{Mesaros2013,
abstract = {This paper presents an overview of methods and applications dealing with analysis of singing voice audio signals, related to singer identity and lyrics content of the singing. Singer identification in polyphonic music is based on general audio classification methods. The presence of instruments is detrimental to voice identification performance, and eliminating the effect of instrumental accompaniment is an important aspect of the problem. The results show that classification of singing voices can be done robustly in polyphonic music when using source separation. Lyrics transcription is approached as a speech recognition problem, with specific elements for dealing with singing voice. The variability of phonation in singing poses a significant challenge to the speech recognition approach. The word recognition accuracy of the lyrics transcription from singing is quite low, but it is shown to be useful in a query-by-singing application, for performing a textual search based on the words recognized from the query. A system for automatic alignment of lyrics and audio is also presented, with sufficient performance for facilitating applications such as automatic karaoke annotation or song browsing.},
author = {Mesaros, Annamaria},
doi = {10.1109/SpeD.2013.6682644},
file = {:home/gerardo/Documents/Mendeley Desktop/Mesaros - 2013 - Singing voice identification and lyrics transcription for music information retrieval.pdf:pdf},
isbn = {9781479910656},
journal = {2013 7th Conference on Speech Technology and Human - Computer Dialogue, SpeD},
pages = {1--10},
title = {{Singing voice identification and lyrics transcription for music information retrieval}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=6682644},
year = {2013}
}
@article{Mesaros2011,
author = {Mesaros, Annamaria and Virtanen, T},
file = {:home/gerardo/Documents/Mendeley Desktop/Mesaros, Virtanen - 2011 - Automatic Understanding of Lyrics From Singing.pdf:pdf},
journal = {Korkeakoulunkatu 1, 33720, TAMPERE},
pages = {1--6},
title = {{Automatic Understanding of Lyrics From Singing}},
url = {http://www.akustinenseura.fi/wp-content/uploads/2013/08/Mesaros.pdf},
year = {2011}
}
@article{Mesaros2010b,
abstract = {The paper considers the task of recognizing phonemes and wor ds from a singing input by using a phonetic hidden Markov model recognizer. The system is targeted to both monophonic singing and singing in polyphonic music. A vocal separation algorithm is applied to separate the singing from polyphonic music. Due to the lack of annotated singing databases, the recognizer is trained using speech and linearly adapted to singing. Global adaptation t o singing is found to improve singing recognition performance. Further improvement is obtained by gender-specific adaptation. We also study adaptation with multiple base classes defined by either phonetic or acoustic similarity. We test phoneme-level and word-level n -gram language models. The phoneme language models are trained on the speech database text. The large-vocabulary word-level language model is trained on a database of textual lyrics. Two applications are presented. The recognizer is used to align textual lyrics to vocals in polyphonic music, obtaining an average error of 0.94 seconds for line-level alignment. A query-by-singing retrieval application based on the recognized words is also constructed; in 57{\%} of the cases, the first retrieved song is the correct one.},
annote = {1 - Difference in Normal Speech and Singing
- Normal speech : The spectrum vary freely and the pitch or loudness is used to express emotions.
- Singing speech : The pitch, loudness and timbre have to be controlled - no free changes

2 - Pitch range
in singing is espected to be higher than normal speec. Morover, in singing in almost constant between notes and in normal speech varies 
In spectrum, singing pitch - the variation in phoneme is smaller than variation in normal speech.

3 - This Singing Recognition System
The models in this singing recognition system were 39 monophone HMMs plus silence and short pauses.(System implemented with The Hidden Markov Model Toolkit (HTK) http://htk.eng.cam.ac.uk)

3.1 - Adaptation
Adatpation to singing -{\textgreater} first training to speech, then adaptation to singing.
Maximum liner likelihood regression technique used in all gaussians in all states. (global adaptation) with 2 pass procedure
Gauss MLLR adaptation u{\^{}} = Au +b where A = lineartransform Matrix - b = bias vecto. and s{\^{}} = AsA

3.2 - N-Gram Language Model 
Vocabulary from the corpus. Corpus created with song lyrics with goal of 5K vocabulary.

3.3 - Separation of Vocal from polythonic
Vocal separation algorithm. [29]

4- Testing and adaptation
monophonic- 19 male, 30 female of popular songs. total 30 min with 4770 phoneme instance
poliphonic- 17 popular songs. total 30 min and 100 fragments of singing and instrumental accompaniment.
lyrics manually annotated for reference. transcription used in adaptation and evaluation.
A song only in tet or adaptation
Singer in both

5 - Evaluation
Crrect recognition, accuracy and error rate
N = Total
D = Deletion errors
S = Substitution error
I = Insertion error
correct = N-D-S /N *100
accuracy = N-D-S-I/N *100
error rate = D+S+I/N *100

6 - Results
6.1 - Phoneme recognition
6.1.1 - clean voice
gender adapted models.
with no lenguage model high recognition but lower accuracy, unigram and bigram result less recognition in 5-6 points but improve accuracy
trigram have similar performance than no lenguage model

6.1.2 - poliphonic
No gender adaptation
best performance with trigram but only 30{\%} of correct and 13.8 of accuracy, no language model 23.5 and 5.8 each

6.2 - Word recognition
Vocabulary size 5167
Bigram language model better results than trigram.
trigram results with negative accuracy meaning too many insertions errors.

Results were low for speech recognition.
table 9 of the paper 
Useful for other porpouses.

7 - Applications
7.1 - Automatic Singing-to-Lyrics Alignment
using an HMM recognizer it is posible to align the lyrics with the corresponding phoneme
USeful for karaoke.

7.2 - Query-by-singing based on Word Recognition
A retrieval system using lyrics.
Allows retrival results with less skilled singers.},
author = {Mesaros, Annamaria and Virtanen, Tuomas},
doi = {10.1155/2010/546047},
file = {:home/gerardo/Documents/Mendeley Desktop/Mesaros, Virtanen - 2010 - Automatic Recognition of Lyrics in Singing.pdf:pdf},
journal = {EURASIP Journal on Audio, Speech, and Music Processing},
number = {4},
pages = {11},
title = {{Automatic Recognition of Lyrics in Singing}},
url = {http://dl.acm.org/citation.cfm?id=1863626},
volume = {2010},
year = {2010}
}
@article{Miao2014,
abstract = {The Kaldi toolkit is becoming popular for constructing automated speech recognition (ASR) systems. Meanwhile, in recent years, deep neural networks (DNNs) have shown state-of-the-art performance on various ASR tasks. This document describes our open-source recipes to implement fully-fledged DNN acoustic modeling using Kaldi and PDNN. PDNN is a lightweight deep learning toolkit developed under the Theano environment. Using these recipes, we can build up multiple systems including DNN hybrid systems, convolutional neural network (CNN) systems and bottleneck feature systems. These recipes are directly based on the Kaldi Switchboard 110-hour setup. However, adapting them to new datasets is easy to achieve.},
archivePrefix = {arXiv},
arxivId = {1401.6984},
author = {Miao, Yajie},
eprint = {1401.6984},
file = {:home/gerardo/Documents/Mendeley Desktop/Miao - 2014 - Kaldi PDNN Building DNN-based ASR Systems with Kaldi and PDNN.pdf:pdf},
journal = {CoRR},
pages = {1--4},
title = {{Kaldi+ PDNN: Building DNN-based ASR Systems with Kaldi and PDNN}},
url = {http://arxiv.org/abs/1401.6984},
volume = {abs/1401.6},
year = {2014}
}
@inproceedings{povey2011kaldi,
author = {Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and Others},
booktitle = {IEEE 2011 workshop on automatic speech recognition and understanding},
file = {:home/gerardo/Documents/Mendeley Desktop/Povey et al. - 2011 - The Kaldi Speech Recognition Toolkit.pdf:pdf},
number = {EPFL-CONF-192584},
organization = {IEEE Signal Processing Society},
title = {{The Kaldi speech recognition toolkit}},
year = {2011}
}
@article{Rybach,
author = {Rybach, D and Bisani, M and Dreuw, P and Gollan, C and Hahn, S and Heigold, G and Hoffmeister, B and Kanthak, S and Lehnen, P},
file = {:home/gerardo/Documents/Mendeley Desktop/Rybach et al. - Unknown - RASR – The RWTH Aachen University Open Source Speech Recognition Toolkit.pdf:pdf},
pages = {2--5},
title = {{RASR – The RWTH Aachen University Open Source Speech Recognition Toolkit}}
}
@article{Walker2004,
abstract = {Sphinx-4 is a flexible, modular and pluggable framework to help foster new innovations in the core research of hidden Markov model (HMM) speech recognition systems. The design of Sphinx-4 is based on patterns that have emerged from the design of past systems as well as new requirements based on areas that researchers currently want to explore. To exercise this framework, and to provide researchers with a “researchready” system, Sphinx-4 also includes several implementations of both simple and state-of-the-art techniques. The framework and the implementations are all freely available via open source.},
author = {Walker, Willie and Lamere, Paul and Kwok, Philip and Raj, Bhiksha and Singh, Rita and Gouvea, Evandro and Wolf, Peter and Woelfel, Joe},
doi = {10.1.1.91.4704},
file = {:home/gerardo/Documents/Mendeley Desktop/Walker et al. - 2004 - Sphinx-4 A Flexible Open Source Framework for Speech Recognition.pdf:pdf},
journal = {Smli},
number = {TR-2004-139},
pages = {1--9},
title = {{Sphinx-4 : A Flexible Open Source Framework for Speech Recognition}},
year = {2004}
}
@article{Young2009,
abstract = {HTK is a toolkit for building Hidden Markov Models (HMMs). HMMs can be used to model any time series and the core of HTK is similarly general-purpose. However, HTK is primarily designed for building HMM-based speech processing tools, in particular recognisers. Thus, much of the infrastructure support in HTK is dedicated to this task.},
author = {Young, S. J. and Evermann, G. and Gales, M. J. F. and Hain, T. and Kershaw, D. and Liu, X. and Moore, G. and Odell, J. and Ollason, D. and Povey, D. and Valtchev, V. and Woodland, P. C.},
doi = {http://htk.eng.cam.ac.uk},
file = {:home/gerardo/Documents/Mendeley Desktop/Young et al. - 2009 - The HTK Book (for HTK Version 3.4).pdf:pdf},
journal = {Cambridge University Engineering Department},
number = {July 2000},
pages = {384},
title = {{The HTK Book (for HTK Version 3.4)}},
url = {http://htk.eng.cam.ac.uk},
year = {2009}
}
@phdthesis{RosilloGil2016,
author = {{Rosillo Gil}, V{\'{i}}ctor},
booktitle = {In Practice},
file = {:home/gerardo/Documents/Mendeley Desktop/ASR with Kaldi toolkit MEMORY.pdf:pdf},
keywords = {Rosillo2016},
title = {{Automatic Speech Recognition with Kaldi toolkit}},
url = {http://upcommons.upc.edu/handle/2117/83420},
year = {2016}
}
