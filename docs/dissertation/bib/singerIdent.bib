@article{Ellis2006,
author = {Ellis, Daniel P W},
file = {:home/groa/Documents/Mendeley Desktop/Ellis06-musicinfo-cacm.pdf:pdf},
journal = {Communications of the ACM},
number = {8},
title = {{Extracting Information From Music Audio}},
volume = {49},
year = {2006}
}
@article{Kan2008,
abstract = {We present LyricAlly, a prototype that automatically aligns acoustic musical signals with their corresponding textual lyrics, in a manner similar to manually-aligned karaoke. We tackle this problem based on a multimodal approach, using an appropriate pairing of audio and text processing to create the resulting prototype. LyricAlly's acoustic signal processing uses standard audio features but constrained and informed by the musical nature of the signal. The resulting detected hierarchical rhythm structure is utilized in singing voice detection and chorus detection to produce results of higher accuracy and lower computational costs than their respective baselines. Text processing is employed to approximate the length of the sung passages from the lyrics. Results show an average error of less than one bar for per-line alignment of the lyrics on a test bed of 20 songs (sampled from CD audio and carefully selected for variety). We perform a comprehensive set of system-wide and per-component tests and discuss their results. We conclude by outlining steps for further development.},
author = {Kan, Min Yen and Wang, Ye and Iskandar, Denny and Nwe, Tin Lay and Shenoy, Arun},
doi = {10.1109/TASL.2007.911559},
file = {:home/groa/Documents/Mendeley Desktop/Kan et al. - 2008 - LyricAlly Automatic synchronization of textual lyrics to acoustic music signals.pdf:pdf},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Acoustic signal detection,Acoustic signal processing,Music,Text processing},
number = {2},
pages = {338--349},
title = {{LyricAlly: Automatic synchronization of textual lyrics to acoustic music signals}},
volume = {16},
year = {2008}
}
@article{Mesaros2007,
abstract = {This paper evaluates methods for singer identification in polyphonic music, based on pattern classification together with an algorithm for vocal separation. Classification strategies include the discriminant functions, Gaussian mixture model (GMM)-based maximum likelihood classifier and nearest neighbour classifiers using Kullback-Leibler divergence between the GMMs. A novel method of estimating the symmetric Kullback-Leibler distance between two GMMs is proposed. Two different approaches to singer identification were studied: one where the acoustic features were extracted directly from the polyphonic signal and one where the vocal line was first separated from the mixture using a predominant melody transcription system. The methods are evaluated using a database of songs where the level difference between the singing and the accompaniment varies. It was found that vocal line separation enables robust singer identification down to 0dB and-5dB singer-to-accompaniment ratios. 1},
author = {Mesaros, Annamaria and Virtanen, Tuomas and Klapuri, Anssi},
file = {:home/groa/Documents/Mendeley Desktop/Mesaros, Virtanen, Klapuri - 2007 - Singer identification in polyphonic music using vocal separation and pattern recognition methods.pdf:pdf},
isbn = {978-3-85403-218},
journal = {In Proc. 7th International Conference on Music Information Retrieval},
keywords = {Singing Classification},
mendeley-tags = {Singing Classification},
pages = {375--378},
title = {{Singer identification in polyphonic music using vocal separation and pattern recognition methods}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.161.5270},
year = {2007}
}
@inproceedings{Smit2007,
abstract = {Automatically identifying sections of solo voices or instruments within a large corpus of music recordings would be useful, for example, to construct a library of isolated instruments to train signal models. We consider several ways to identify these sections, including a baseline classifier trained on conventional speech features. Our best results, achieving frame level precision and recall of around 70{\%}, come from an approach that attempts to track the local periodicity of an assumed solo musical voice, then classifies the segment as a genuine solo or not on the basis of what proportion of the energy can be canceled by a comb filter constructed to remove just that periodicity.},
address = {New Paltz, NY},
author = {Smit, C. and Ellis, D. P. W.},
booktitle = {Applications of Signal Processing to Audio and Acoustics, 2007 IEEE Workshop},
doi = {10.1109/ASPAA.2007.4393045},
file = {:home/groa/Documents/Mendeley Desktop/Smit, Ellis - 2007 - Solo Voice Detection Via Optimal Cancellation.pdf:pdf},
isbn = {9781424416196},
keywords = {Singing Classification},
mendeley-tags = {Singing Classification},
pages = {207--210},
publisher = {IEEE},
title = {{Solo Voice Detection Via Optimal Cancellation}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4393045},
year = {2007}
}
@article{Tsai2006,
abstract = {In this paper, we investigate the problem of automatic singer identification, detection and tracking in popular music recordings with one or multiple singers. This problem reflects an important issue in multimedia applications that require the transcription and indexing of music data to meet the increasing demand for content-based information retrieval. The major challenges for this study arise from the fact that a singer's voice tends to be arbitrarily altered from time to time and is inextricably intertwined with the signal of the background accompaniment. To determine who is singing, or whether or when a particular singer is present in a music recording, methods are presented for separating vocal from nonvocal regions, for isolating singers' vocal characteristics from background music, and for distinguishing singers from one another. Experimental evaluations conducted on a pop music database consisting of solo and duet tracks confirm the validity of the proposed methods.},
author = {Tsai, Wei Ho and Wang, Hsin Min},
doi = {10.1109/TSA.2005.854091},
file = {:home/groa/Documents/Mendeley Desktop/Tsai, Wang - 2006 - Automatic singer recognition of popular music recordings via estimation and modeling of solo vocal signals.pdf:pdf},
isbn = {8862278837},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
keywords = {Music information retrieval,Singer detection,Singer identification,Singer tracking,Singing Classification},
mendeley-tags = {Singing Classification},
number = {1},
pages = {330--341},
title = {{Automatic singer recognition of popular music recordings via estimation and modeling of solo vocal signals}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1561289},
volume = {14},
year = {2006}
}
@inproceedings{Tsai2008,
abstract = {The problem of identifying singers in music recordings has received considerable attention with the explosive growth of the Internet and digital media. Although a number of studies on automatic singer identification from acoustic features have been reported, most systems to date, however, reliably establish the identity of singers in solo recordings only. The research presented in this paper attempts to automatically identify singers in music recordings that contain overlapping singing voices. Two approaches to overlapping singer identification are proposed and evaluated. Results obtained demonstrate the feasibility of the systems},
address = {Philadelphia},
author = {Tsai, Wei-Ho and Liao, Shih-Jie and Lai, Catherine},
booktitle = {9th International Conference of Music Information Retrieval},
file = {:home/groa/Documents/Mendeley Desktop/Tsai, Liao, Lai - 2008 - Automatic Identification of Simultaneous Singers in Duet Recordings.pdf:pdf},
isbn = {9780615248493},
keywords = {Singing Classification},
mendeley-tags = {Singing Classification},
pages = {115--120},
title = {{Automatic Identification of Simultaneous Singers in Duet Recordings.}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=OHp3sRnZD-oC{\&}oi=fnd{\&}pg=PA115{\&}dq="reliably+establish+the+identity+of+singers+in"+"to+identify+and+index+singers+in+their"+"a+robust+automatic+singer+identification+system"+"date,+however,+reliably+establish+the+id},
year = {2008}
}
@article{Weiss2010,
abstract = {We present a system for model-based source separation for use on single channel speech mixtures where the precise source characteristics are not known a priori. The sources are modeled using hidden Markov models (HMM) and separated using factorial HMM methods. Without prior speaker models for the sources in the mixture it is difficult to exactly resolve the individual sources because there is no way to determine which state corresponds to which source at any point in time. This is solved to a small extent by the temporal constraints provided by the Markov models, but permutations between sources remains a significant problem. We overcome this by adapting the models to match the sources in the mixture. We do this by representing the space of speaker variation with a parametric signal model-based on the eigenvoice technique for rapid speaker adaptation. We present an algorithm to infer the characteristics of the sources present in a mixture, allowing for significantly improved separation performance over that obtained using unadapted source models. The algorithm is evaluated on the task defined in the 2006 Speech Separation Challenge [Cooke, M.P., Lee, T.-W., 2008. The 2006 Speech Separation Challenge. Computer Speech and Language] and compared with separation using source-dependent models. Although performance is not as good as with speaker-dependent models, we show that the system based on model adaptation is able to generalize better to held out speakers. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Weiss, Ron J. and Ellis, Daniel P W},
doi = {10.1016/j.csl.2008.03.003},
file = {:home/groa/Documents/Mendeley Desktop/1-s2.0-S088523080800017X-main.pdf:pdf},
isbn = {0885-2308},
issn = {08852308},
journal = {Computer Speech and Language},
keywords = {Eigenvoice,Model adaptation,Source separation},
number = {1},
pages = {16--29},
publisher = {Elsevier Ltd},
title = {{Speech separation using speaker-adapted eigenvoice speech models}},
url = {http://dx.doi.org/10.1016/j.csl.2008.03.003},
volume = {24},
year = {2010}
}
